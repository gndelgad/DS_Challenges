{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data challenge LinkValue\n",
    "\n",
    "**Author:** Gabriel Delgado (gabriel.delgado@alumni.polytechnique.org)\n",
    "<br>\n",
    "<br>\n",
    "**Decription:** The dataset contains the following informations about the clients reviews of a product in PriceMinister: review ID, review content, review stars, product ID and target (uselfulness of the review).\n",
    "<br>\n",
    "<br>\n",
    "**Objective:** Predict if the review of a product by a client is useful or not for other clients. The scoring will be measured using the area under the curve ROC (AUC) metric.\n",
    "<br>\n",
    "<br>\n",
    "**Methodology:** This is a problem of binary classification. For each review, we will only focus on the review's content since the review's title doesn't give substantial additional information and the number of stars of the review, as it will be seen later, doesn't have a real impact on the target value. In order to perform machine learning on the texts, we turn the review's content into numerical feature vectors using a bag of words representation via tf-idf (Term Frequency times Inverse Document Frequency). Three approaches are tested to select the desired features (words):\n",
    "* The 99% most significant words (i.e. we ignore terms that appear in less than 1% of the set of reviews). We try to avoid thus overfitting;\n",
    "* The totality of extracted words within the training dataset;\n",
    "* Select the first k principal components of a latent semantic analysis (or truncated SVD).\n",
    "\n",
    "For each one of this choices we train different prediction models (logistic regression, random forest, etc.) and we finally keep the one with the best performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "# Feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Prediction models and selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Metrics and cross validation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = \"C:/WinPython-64bit-2.7.10.3/notebooks/Review_Challenge/\"\n",
    "path = \"C:/Users/gabriel.delgado-keef/Dropbox/Professionnel/LinkValue/Review_Challenge/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load files\n",
    "df = pd.read_csv(path+\"train.csv\",sep=\";\")\n",
    "df_test = pd.read_csv(path+\"test.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_content</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>product</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>En appelant un acheteur pour demander si l'écr...</td>\n",
       "      <td>La Police s'inscrit en acheteur privé sur Pric...</td>\n",
       "      <td>5</td>\n",
       "      <td>2fbb619e3606f9b7c213e858a109cda771aa2c47ce50d5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alors, là, on a affaire au plus grand Navet ja...</td>\n",
       "      <td>Chef D'Oeuvre Absolu en vue...</td>\n",
       "      <td>5</td>\n",
       "      <td>7b56d9d378d9e999d293f301ac43d044cd7b4786d09afb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Effet garanti sur la terrase. Ils donnent immé...</td>\n",
       "      <td>Effet garanti sur la terrase. Ils donnent immé...</td>\n",
       "      <td>3</td>\n",
       "      <td>7b37bf5dcb2fafd9229897910318a7dfa11a04ca36893c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                     review_content  \\\n",
       "0   0  En appelant un acheteur pour demander si l'écr...   \n",
       "1   1  Alors, là, on a affaire au plus grand Navet ja...   \n",
       "2   2  Effet garanti sur la terrase. Ils donnent immé...   \n",
       "\n",
       "                                        review_title  review_stars  \\\n",
       "0  La Police s'inscrit en acheteur privé sur Pric...             5   \n",
       "1                     Chef D'Oeuvre Absolu en vue...             5   \n",
       "2  Effet garanti sur la terrase. Ils donnent immé...             3   \n",
       "\n",
       "                                             product  Target  \n",
       "0  2fbb619e3606f9b7c213e858a109cda771aa2c47ce50d5...       0  \n",
       "1  7b56d9d378d9e999d293f301ac43d044cd7b4786d09afb...       1  \n",
       "2  7b37bf5dcb2fafd9229897910318a7dfa11a04ca36893c...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how the data looks like\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........       ..........         .........         ..........       ...........        .............\n"
     ]
    }
   ],
   "source": [
    "# We remark that the content of same reviews is completely useless\n",
    "print(df[\"review_content\"].iloc[5224])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Impact of the review stars classes over the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probility of a review to be useful (Target = 1) for each review stars class:\n",
      "review_stars\n",
      "1    0.533504\n",
      "2    0.457665\n",
      "3    0.479939\n",
      "4    0.573273\n",
      "5    0.565109\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_stars = df.pivot_table(values='Target',index=['review_stars'],aggfunc=lambda x: x.mean())\n",
    "print '\\nProbility of a review to be useful (Target = 1) for each review stars class:' \n",
    "print target_stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each one of the conditional probabilities are close to the same value (around 50%), we can deduce that the number of stars of a review does not impact the target value (in other words they are independent). Comment: If too few data was classified as 0 or 1, then we had had to ask for more data to the client or try to retrieve it elsewhere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spliting the training dataset into \"train\" and \"test\" sets in order to select the best prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We set aside 20% of the data as test set \n",
    "Review_train, Review_test, Target_train, Target_test = train_test_split(df[\"review_content\"], df[\"Target\"],\n",
    "                                                    test_size=0.2, random_state=123, stratify=df[\"Target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting features from the training data using a sparse tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Ignoring terms that appear in less than 1% of the set of reviews ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=0.01,max_df=0.5, strip_accents='unicode') \n",
    "X_train_tfidf_1 = vectorizer.fit_transform(Review_train.values)\n",
    "# Extracting features from the test data using the same training vectorizer\n",
    "X_test_tfidf_1 = vectorizer.transform(Review_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'10', u'absolument', u'achat', u'achete', u'acheter', u'adore', u'agreable', u'ai', u'aime', u'ainsi', u'aise', u'album', u'alors', u'amateurs', u'annees', u'ans', u'appareil', u'apres', u'article', u'assez', u'attention', u'au', u'aucun', u'aussi', u'autre', u'autres', u'aux', u'avant', u'avec', u'avis', u'avoir', u'beau', u'beaucoup', u'belle', u'belles', u'bien', u'bon', u'bonne', u'bref', u'ca', u'cadeau', u'car', u'carte', u'cartes', u'cd', u'ce', u'cela', u'celui', u'ces', u'cet', u'cette', u'ceux', u'chaque', u'cher', u'chez', u'ci', u'collection', u'collectionneurs', u'comme', u'conforme', u'conseille', u'contre', u'cote', u'couleur', u'couleurs', u'dans', u'decu', u'deja', u'depuis', u'des', u'design', u'deux', u'dire', u'disque', u'dommage', u'donc', u'donne', u'dont', u'du', u'dvd', u'ecran', u'effet', u'efficace', u'elle', u'elles', u'en', u'encore', u'enfants', u'enfin', u'entre', u'envoi', u'epoque', u'est', u'et', u'etait', u'etat', u'ete', u'etre', u'eu', u'excellent', u'excellente', u'facile', u'facilement', u'faire', u'fait', u'fan', u'fans', u'faut', u'figurine', u'film', u'fin', u'fois', u'fonctionne', u'genial', u'genre', u'grace', u'grand', u'grande', u'histoire', u'ideal', u'il', u'ils', u'image', u'indispensable', u'interessant', u'jamais', u'je', u'jeu', u'jeux', u'joli', u'jolie', u'jouer', u'jour', u'jours', u'juste', u'la', u'le', u'lecteur', u'les', u'leur', u'lire', u'livraison', u'livre', u'lui', u'ma', u'machine', u'magnifique', u'main', u'mais', u'mal', u'marche', u'marque', u'me', u'meilleur', u'meme', u'merci', u'mes', u'mettre', u'mieux', u'modele', u'moi', u'moins', u'mois', u'mon', u'monde', u'musique', u'ne', u'neuf', u'niveau', u'non', u'nous', u'objet', u'on', u'ont', u'ou', u'par', u'parfait', u'parfaitement', u'part', u'pas', u'passe', u'pc', u'permet', u'petit', u'petite', u'petits', u'peu', u'peut', u'photo', u'photos', u'piece', u'place', u'plaisir', u'plus', u'plusieurs', u'plutot', u'point', u'porte', u'porter', u'pour', u'pratique', u'premier', u'prendre', u'prise', u'prix', u'probleme', u'produit', u'produits', u'puissance', u'qu', u'qualite', u'quand', u'quant', u'que', u'quelques', u'qui', u'rapide', u'rapidement', u'rapport', u'rare', u'recommande', u'recommander', u'recu', u'redire', u'reste', u'rien', u'robe', u'sa', u'saisir', u'sans', u'savoir', u'se', u'sent', u'serie', u'ses', u'seul', u'si', u'simple', u'simplement', u'sinon', u'soit', u'solide', u'son', u'sont', u'sous', u'suis', u'super', u'superbe', u'sur', u'surtout', u'sympa', u'taille', u'telephone', u'temps', u'tissu', u'top', u'toujours', u'tous', u'tout', u'toute', u'toutes', u'tres', u'trop', u'trouve', u'trouver', u'un', u'une', u'utile', u'utilisation', u'utilise', u'utiliser', u'va', u'vaut', u'vendeur', u'version', u'vetement', u'video', u'vie', u'vite', u'voir', u'vos', u'votre', u'vous', u'vrai', u'vraiment', u'vu']\n",
      "\n",
      "Number of features: 286\n"
     ]
    }
   ],
   "source": [
    "print vectorizer.get_feature_names()\n",
    "print '\\nNumber of features: %d' % len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Using the totality of extracted words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, strip_accents='unicode') \n",
    "X_train_tfidf_T = vectorizer.fit_transform(Review_train.values)\n",
    "X_test_tfidf_T = vectorizer.transform(Review_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features: 54995\n"
     ]
    }
   ],
   "source": [
    "print '\\nNumber of features: %d' % len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Selecting the first k principal components of a latent semantic analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this case we take the first 100 principal components\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_train_tfidf_svd = svd.fit_transform(X_train_tfidf_T)\n",
    "X_test_tfidf_svd = svd.transform(X_test_tfidf_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The explained variance of the SVD 0.197306\n"
     ]
    }
   ],
   "source": [
    "# We would need at least 1000 components to explain 50% of the variance. We keep 100 only for illustration purposes. \n",
    "print'The explained variance of the SVD %f' % svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General testing function measuring the accuracy of the predictor on the test data set via AUC\n",
    "def classification_model(model, input_train, output_train, input_test, output_test):\n",
    "    #Fit the model:\n",
    "    model.fit(input_train,output_train)\n",
    "  \n",
    "    #Make predictions on train and test datasets:\n",
    "    predictions_train = model.predict_proba(input_train)\n",
    "    predictions_test = model.predict_proba(input_test)\n",
    "  \n",
    "    #Print scoring\n",
    "    auc = roc_auc_score(output_train, predictions_train[:,1])\n",
    "    print \"Train data scoring : %s\" % \"{0:.3}\".format(auc)\n",
    "    \n",
    "    auc = roc_auc_score(output_test, predictions_test[:,1])\n",
    "    print \"Test data scoring : %s\" % \"{0:.3}\".format(auc)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**4.1 Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=30,n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.973\n",
      "Test data scoring : 0.708\n"
     ]
    }
   ],
   "source": [
    "# 3.1 features selection\n",
    "classification_model(model, X_train_tfidf_1, Target_train.values, X_test_tfidf_1, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.846\n",
      "Test data scoring : 0.711\n"
     ]
    }
   ],
   "source": [
    "# 3.2 features selection\n",
    "classification_model(model, X_train_tfidf_T, Target_train.values, X_test_tfidf_T, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.998\n",
      "Test data scoring : 0.695\n"
     ]
    }
   ],
   "source": [
    "# 3.3 features selection\n",
    "classification_model(model, X_train_tfidf_svd, Target_train.values, X_test_tfidf_svd, Target_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.677\n",
      "Test data scoring : 0.671\n"
     ]
    }
   ],
   "source": [
    "# 3.1 features selection\n",
    "classification_model(model, X_train_tfidf_1, Target_train.values, X_test_tfidf_1, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.845\n",
      "Test data scoring : 0.725\n"
     ]
    }
   ],
   "source": [
    "# 3.2 features selection\n",
    "classification_model(model, X_train_tfidf_T, Target_train.values, X_test_tfidf_T, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.669\n",
      "Test data scoring : 0.668\n"
     ]
    }
   ],
   "source": [
    "# 3.3 features selection\n",
    "classification_model(model, X_train_tfidf_svd, Target_train.values, X_test_tfidf_svd, Target_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 SVM (support vector machine)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log',alpha=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.66\n",
      "Test data scoring : 0.651\n"
     ]
    }
   ],
   "source": [
    "# 3.1 features selection\n",
    "classification_model(model, X_train_tfidf_1, Target_train.values, X_test_tfidf_1, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.878\n",
      "Test data scoring : 0.719\n"
     ]
    }
   ],
   "source": [
    "# 3.2 features selection\n",
    "classification_model(model, X_train_tfidf_T, Target_train.values, X_test_tfidf_T, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.664\n",
      "Test data scoring : 0.661\n"
     ]
    }
   ],
   "source": [
    "# 3.3 features selection\n",
    "classification_model(model, X_train_tfidf_svd, Target_train.values, X_test_tfidf_svd, Target_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4 Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.642\n",
      "Test data scoring : 0.636\n"
     ]
    }
   ],
   "source": [
    "# 3.1 features selection\n",
    "classification_model(model, X_train_tfidf_1, Target_train.values, X_test_tfidf_1, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scoring : 0.847\n",
      "Test data scoring : 0.716\n"
     ]
    }
   ],
   "source": [
    "# 3.2 features selection\n",
    "classification_model(model, X_train_tfidf_T, Target_train.values, X_test_tfidf_T, Target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3.3 features selection not applicable (Input X must be non-negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result we can conclude:\n",
    "\n",
    "* The best scorings are obtained using as features the ensemble of words within the client's reviews;\n",
    "* Logistic regression and SVM seem to show the best accuracies in terms of AUC ROC (0.7-0.8). These values remain fair but not good or excellent as expected. \n",
    "\n",
    "Therefore we propose as candidate predictor the simplest model (logistic regression classifier, which is easier to interpret and thus transfert to a client) and we predict the probabilities on the original test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, strip_accents='unicode') \n",
    "X_train_tfidf = vectorizer.fit_transform(df[\"review_content\"])\n",
    "X_test_tfidf = vectorizer.transform(df_test[\"review_content\"])\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf,df[\"Target\"])\n",
    "predictions = model.predict_proba(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_candidate_submission = df_test.drop([\"review_content\",\"review_title\",\"review_stars\",\"product\"]\n",
    "                                       ,axis=1)\n",
    "df_candidate_submission[\"Target\"] = predictions[:,1].round(3)\n",
    "df_candidate_submission.to_csv('candidate_submission.csv',sep=\";\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
